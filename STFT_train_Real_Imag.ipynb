{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "from collections import defaultdict, Counter\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import librosa\n",
    "import random as rn\n",
    "from keras.layers import Dense\n",
    "from keras import Input\n",
    "#from keras.engine import Model\n",
    "from keras.layers import Dense, TimeDistributed, Dropout, Bidirectional, GRU, BatchNormalization, Activation, LeakyReLU, LSTM, Flatten, RepeatVector, Permute, Multiply, Conv2D, MaxPooling2D\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "import csv \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import keras\n",
    "from keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/USER/Desktop/spcup_2022/audiofile/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 257, 42)\n",
      "(5000, 257, 42)\n",
      "(5000, 5)\n"
     ]
    }
   ],
   "source": [
    "X_real = []\n",
    "X_imag = []\n",
    "Y = []\n",
    "X_shape_list = []\n",
    "categories = [\"0\",\"1\",\"2\",\"3\",\"4\"]\n",
    "num_classes = len(categories)\n",
    "\n",
    "\n",
    "for filename in os.listdir(f'C:/Users/USER/Desktop/spcup_2022/audiofile/'):\n",
    "    audioname = f'C:/Users/USER/Desktop/spcup_2022/audiofile/{filename}'\n",
    "    y, sr = librosa.load(audioname, duration=1, sr = 16000)  # 모두 1초까지만 자름\n",
    "    stft = librosa.stft(y, n_fft=512, hop_length=384)   # 일반적으로 1/4 가량 겹치게 함\n",
    "    real = stft.real\n",
    "    imag = stft.imag\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(real)\n",
    "    real = scaler.transform(real)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(imag)\n",
    "    imag = scaler.transform(imag)\n",
    "    \n",
    "    X_real.append(real)\n",
    "    X_imag.append(imag)   \n",
    "    \n",
    "for idex, category in enumerate(categories):\n",
    "    label = [0 for i in range(num_classes)]\n",
    "    label[idex] = 1\n",
    "    for j in range(1000):\n",
    "        Y.append(label)\n",
    "\n",
    "X_real = np.array(X_real)\n",
    "X_imag = np.array(X_imag)\n",
    "Y = np.array(Y)\n",
    "print(X_real.shape)\n",
    "print(X_imag.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].shape, X[1].shape, X[318].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_real\n",
      "(4000, 257, 42)\n",
      "(1000, 257, 42)\n",
      "(4000, 5)\n",
      "(1000, 5)\n",
      "X_imag\n",
      "(4000, 257, 42)\n",
      "(1000, 257, 42)\n",
      "(4000, 5)\n",
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "X_real_train = np.concatenate((X_real[0:800],X_real[1000:1800],X_real[2000:2800],X_real[3000:3800],X_real[4000:4800]), axis = 0)\n",
    "X_real_test = np.concatenate((X_real[800:1000],X_real[1800:2000],X_real[2800:3000],X_real[3800:4000],X_real[4800:5000]), axis = 0)\n",
    "Y_real_train = np.concatenate((Y[0:800],Y[1000:1800],Y[2000:2800],Y[3000:3800],Y[4000:4800]), axis = 0)\n",
    "Y_real_test = np.concatenate((Y[800:1000],Y[1800:2000],Y[2800:3000],Y[3800:4000],Y[4800:5000]), axis = 0)\n",
    "\n",
    "X_imag_train = np.concatenate((X_imag[0:800],X_imag[1000:1800],X_imag[2000:2800],X_imag[3000:3800],X_imag[4000:4800]), axis = 0)\n",
    "X_imag_test = np.concatenate((X_imag[800:1000],X_imag[1800:2000],X_imag[2800:3000],X_imag[3800:4000],X_imag[4800:5000]), axis = 0)\n",
    "Y_imag_train = np.concatenate((Y[0:800],Y[1000:1800],Y[2000:2800],Y[3000:3800],Y[4000:4800]), axis = 0)\n",
    "Y_imag_test = np.concatenate((Y[800:1000],Y[1800:2000],Y[2800:3000],Y[3800:4000],Y[4800:5000]), axis = 0)\n",
    "\n",
    "print('X_real')\n",
    "print(X_real_train.shape)\n",
    "print(X_real_test.shape)\n",
    "print(Y_real_train.shape)\n",
    "print(Y_real_test.shape)\n",
    "print('X_imag')\n",
    "print(X_imag_train.shape)\n",
    "print(X_imag_test.shape)\n",
    "print(Y_imag_train.shape)\n",
    "print(Y_imag_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델에 들어가려면 4차원으로 바꿔줘야함\n",
    "X_real_train = X_real_train.reshape(-1,257,42,1)\n",
    "X_real_test = X_real_test.reshape(-1,257,42,1)\n",
    "\n",
    "X_imag_train = X_imag_train.reshape(-1,257,42,1)\n",
    "X_imag_test = X_imag_test.reshape(-1,257,42,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(257, 42, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - 30s 472ms/step - loss: 1.1103 - accuracy: 0.5807\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 29s 457ms/step - loss: 0.5748 - accuracy: 0.8518\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 30s 478ms/step - loss: 0.4178 - accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 30s 478ms/step - loss: 0.3494 - accuracy: 0.9620\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 29s 467ms/step - loss: 0.2980 - accuracy: 0.9803\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 29s 456ms/step - loss: 0.2656 - accuracy: 0.9902\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 31s 488ms/step - loss: 0.2441 - accuracy: 0.9930\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 29s 463ms/step - loss: 0.2261 - accuracy: 0.9960\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 30s 470ms/step - loss: 0.2122 - accuracy: 0.9955\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 29s 462ms/step - loss: 0.2000 - accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "classifier = model.fit(X_imag_train,\n",
    "                    Y_imag_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(classifier.history['loss'])\n",
    "#plt.plot(classifier.history['accuracy'])\n",
    "plt.legend(['training', 'validation'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 2s - loss: 0.2907 - accuracy: 0.9130 - 2s/epoch - 71ms/step\n",
      "테스트 정확도: 0.9129999876022339\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_real_test,  Y_real_test, verbose=2)\n",
    "print('테스트 정확도:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 2s - loss: 0.4945 - accuracy: 0.8880 - 2s/epoch - 72ms/step\n",
      "테스트 정확도: 0.8880000114440918\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_imag_test,  Y_imag_test, verbose=2)\n",
    "print('테스트 정확도:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_imag_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 2 2\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 2\n",
      " 1 1 2 2 2 2 2 2 2 1 2 2 2 2 1 1 2 2 2 2 2 1 1 1 1 1 2 2 1 2 1 2 2 1 2 2 2\n",
      " 1 2 1 1 2 1 1 1 2 2 2 2 2 1 1 1 2 2 1 2 2 1 2 2 2 1 2 2 2 2 1 3 1 1 2 2 2\n",
      " 2 2 2 2 2 1 2 2 1 2 2 1 2 2 2 2 2 1 2 1 2 2 2 2 1 2 1 2 2 2 2 1 2 2 2 1 1\n",
      " 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 1 2 2 1 2 1 2 2 2 2 2 1 2 2 2 1 2\n",
      " 1 2 2 2 2 2 2 2 2 2 1 1 1 1 1 2 2 2 3 2 1 2 1 2 2 2 1 2 1 1 1 2 2 2 2 2 1\n",
      " 1 2 2 2 2 2 1 2 3 3 3 3 2 3 3 3 3 3 3 2 3 3 3 3 3 3 3 1 3 3 1 3 3 3 3 3 3\n",
      " 3 3 3 1 3 3 3 3 2 3 2 3 3 3 3 3 3 2 3 3 3 3 1 3 3 3 3 3 3 3 2 3 3 1 3 3 3\n",
      " 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 1 3 3 3 3 3 3 3 1 3 3 3 3 3 3 3\n",
      " 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 1 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1 3 3 3 3 1 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4]\n"
     ]
    }
   ],
   "source": [
    "predicted_classes = np.argmax(prediction, axis = 1)\n",
    "print(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
      " 4]\n"
     ]
    }
   ],
   "source": [
    "labels = np.argmax(Y_imag_test, axis=1)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape, predicted_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.where(predicted_classes[0] != labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(predicted_classes != labels)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filename = []\n",
    "for filename in os.listdir(f'C:/Users/USER/Desktop/spcup_2022/audiofile/'):\n",
    "    audioname = f'C:/Users/USER/Desktop/spcup_2022/audiofile/{filename}'\n",
    "    X_filename.append(audioname)\n",
    "X_filename = np.array(X_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_filename = np.concatenate((X_filename[800:1000],X_filename[1800:2000],X_filename[2800:3000],X_filename[3800:4000],X_filename[4800:5000]), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_filename[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 잘못 예측한 오디오 파일들 \n",
    "wrong_predictions = []\n",
    "\n",
    "for i in range(len(index[0])):\n",
    "    wrong_predictions.append(X_test_filename[index[0][i]])\n",
    "    print(X_test_filename[index[0][i]])\n",
    "    \n",
    "print(len(wrong_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘못 예측한거 plot\n",
    "for audio in wrong_predictions:\n",
    "    y, sr = librosa.load(audio, duration=1)  # 모두 1초까지만 자름\n",
    "    stft = np.abs(librosa.stft(y, n_fft=512, hop_length=384))   # 일반적으로 1/4 가량 겹치게 함\n",
    "    spectogram = np.abs(stft)\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(audio)\n",
    "    plt.plot(spectogram) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 잘못 예측한 오디오 파일들 모은 폴더 생성\n",
    "import shutil\n",
    "import os\n",
    " \n",
    "file_source = 'C:/Users/USER/Desktop/spcup_2022/audiofile/'\n",
    "file_destination = 'C:/Users/USER/Desktop/wrong_prediction'\n",
    " \n",
    "get_files = os.listdir(file_source)\n",
    " \n",
    "\n",
    "for i in range(len(wrong_predictions)):\n",
    "    print(wrong_predictions[i][43:])\n",
    "    for g in get_files:\n",
    "        if g == wrong_predictions[i][43:]:\n",
    "            shutil.move(file_source + g, file_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
